{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "header-markdown"
   },
   "source": [
    "# Ticket Urgency Classification\n",
    "\n",
    "This notebook explores, preprocesses, and models customer support ticket data to predict urgency (priority)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "imports-header"
   },
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "id": "ee04fa28"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "import joblib\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from xgboost import XGBClassifier\n",
    "from datasets import load_dataset\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from catboost import CatBoostClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*use_label_encoder.*\")\n",
    "from ticket_urgency_classifier.config import RAW_DATA_DIR, INTERIM_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb1f1a1f",
    "outputId": "9c75ba88-5876-45bc-f762-b2f657c73494"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "data-loading-header"
   },
   "source": [
    "## 2. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7175c63f",
    "outputId": "abb7a52e-2cd5-4160-ab8e-6080462d4679"
   },
   "outputs": [],
   "source": [
    "dataset_file = RAW_DATA_DIR / \"dataset.csv\"\n",
    "if not dataset_file.exists():\n",
    "    print(\"Downloading dataset...\")\n",
    "    ds = load_dataset(\"Tobi-Bueck/customer-support-tickets\")\n",
    "    df_raw = ds['train'].to_pandas()\n",
    "    df_raw.to_csv(dataset_file, index=False)\n",
    "    print(\"Dataset saved.\")\n",
    "else:\n",
    "    print(\"Dataset already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "715be00b",
    "outputId": "6b1e91e8-1ca4-49a3-eb8e-13b03ec57f29"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(RAW_DATA_DIR / \"dataset.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "930a8bbf",
    "outputId": "ea9f8ac7-930d-4da1-adc2-831336237d0f"
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['version', 'answer'], inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(f\"Shape after cleaning: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "id": "feature-eng-header"
   },
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42, stratify=df['priority'])\n",
    "print(f\"Training set size: {df_train.shape}\")\n",
    "print(f\"Test set size: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"\n",
    "    Applies feature engineering to the dataframe.\n",
    "    - Creates 'full_text' by combining subject and body.\n",
    "    - Extracts text statistics (sentiment, word count, etc.).\n",
    "    - Counts occurrences of predefined keywords.\n",
    "    - Creates an interaction feature between 'queue' and 'type'.\n",
    "    \"\"\"\n",
    "    # Combine text fields for analysis\n",
    "    df['full_text'] = df['subject'].fillna(\"\") + \" \" + df['body'].fillna(\"\")\n",
    "    \n",
    "    # Text statistics\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    df['sentiment_score'] = df['full_text'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "    df['word_count'] = df['full_text'].apply(lambda x: len(x.split()))\n",
    "    df['exclamation_count'] = df['full_text'].str.count('!')\n",
    "    df['question_mark_count'] = df['full_text'].str.count(r'\\?')\n",
    "\n",
    "    # Keyword extraction\n",
    "    urgency_keywords = ['payment', 'failed', 'cannot access', 'login error', 'outage', 'urgent', 'asap', 'critical']\n",
    "    question_keywords = ['how to', 'where is', 'can you', 'inquiry', 'question']\n",
    "    bug_keywords = ['error code', 'exception', 'not working', 'crash', 'bug report', 'defect']\n",
    "    \n",
    "    urgency_regex = r'\\b(' + '|'.join(urgency_keywords) + r')\\b'\n",
    "    question_regex = r'\\b(' + '|'.join(question_keywords) + r')\\b'\n",
    "    bug_regex = r'\\b(' + '|'.join(bug_keywords) + r')\\b'\n",
    "\n",
    "    df['urgency_keyword_count'] = df['full_text'].str.count(urgency_regex, flags=re.IGNORECASE)\n",
    "    df['question_keyword_count'] = df['full_text'].str.count(question_regex, flags=re.IGNORECASE)\n",
    "    df['bug_keyword_count'] = df['full_text'].str.count(bug_regex, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Interaction feature\n",
    "    df['queue_type_interaction'] = df['queue'].astype(str) + \"_\" + df['type'].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "# --- 2. Helper Function for Tag Intelligence ---\n",
    "def add_tag_features(df, top_tags_list):\n",
    "    \"\"\"\n",
    "    Adds binary features for the presence of top tags.\n",
    "    \"\"\"\n",
    "    tag_cols = [f'tag_{i}' for i in range(1, 9)]\n",
    "    df['all_tags_set'] = df[tag_cols].apply(lambda x: set(x.dropna()), axis=1)\n",
    "    \n",
    "    for tag in top_tags_list:\n",
    "        col_name = f'tag_{tag.replace(\" \", \"_\")}'\n",
    "        df[col_name] = df['all_tags_set'].apply(lambda x: 1 if tag in x else 0)\n",
    "    \n",
    "    df.drop(columns='all_tags_set', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Applying base feature engineering...\")\n",
    "# Apply the main function to both sets\n",
    "df_train = engineer_features(df_train.copy())\n",
    "df_test = engineer_features(df_test.copy())\n",
    "\n",
    "print(\"Implementing Tag Intelligence...\")\n",
    "# Define original tag columns\n",
    "tag_cols = [f'tag_{i}' for i in range(1, 9)]\n",
    "\n",
    "# Identify top tags from the TRAINING DATA ONLY to prevent data leakage\n",
    "all_tags_series = df_train[tag_cols].stack()\n",
    "top_30_tags = all_tags_series.value_counts().nlargest(30).index.tolist()\n",
    "\n",
    "print(\"\\nTop 30 most common tags identified from the training set:\")\n",
    "print(top_30_tags)\n",
    "\n",
    "# Add the new binary tag features to both sets using the list from the training set\n",
    "df_train = add_tag_features(df_train, top_30_tags)\n",
    "df_test = add_tag_features(df_test, top_30_tags)\n",
    "\n",
    "print(\"\\nNew features have been added to df_train and df_test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "id": "text-vectorization-header"
   },
   "source": [
    "### 3.1. Text Vectorization (TF-IDF and Sentence Transformers)\n",
    "\n",
    "Here we generate and save the vectorized text features. This step can be slow and is only run if the feature files don't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "st-embedding-gen",
    "outputId": "d949dab9-074a-4557-d270-2adfb755c7a8"
   },
   "outputs": [],
   "source": [
    "# Sentence Transformer embeddings - process train and test separately\n",
    "st_file_train = INTERIM_DATA_DIR / \"sentence_embeddings_train.parquet\"\n",
    "st_file_test = INTERIM_DATA_DIR / \"sentence_embeddings_test.parquet\"\n",
    "\n",
    "if not st_file_train.exists() or not st_file_test.exists():\n",
    "    print(\"Generating Sentence Transformer embeddings...\")\n",
    "    embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', device=device)\n",
    "    \n",
    "    # Generate embeddings for training data\n",
    "    text_embeddings_train = embedder.encode(\n",
    "        df_train['full_text'].tolist(),\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=True,\n",
    "        batch_size=64\n",
    "    )\n",
    "    feature_cols = [f\"emb_{i}\" for i in range(text_embeddings_train.shape[1])]\n",
    "    df_embeddings_train = pd.DataFrame(text_embeddings_train, columns=feature_cols)\n",
    "    df_embeddings_train.to_parquet(st_file_train, index=False)\n",
    "    \n",
    "    # Generate embeddings for test data\n",
    "    text_embeddings_test = embedder.encode(\n",
    "        df_test['full_text'].tolist(),\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=True,\n",
    "        batch_size=64\n",
    "    )\n",
    "    df_embeddings_test = pd.DataFrame(text_embeddings_test, columns=feature_cols)\n",
    "    df_embeddings_test.to_parquet(st_file_test, index=False)\n",
    "    \n",
    "    print(\"Embeddings saved.\")\n",
    "else:\n",
    "    print(\"Sentence Transformer embeddings files already exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tfidf-gen",
    "outputId": "ba414231-5142-4dca-bdcb-91c12df4b247"
   },
   "outputs": [],
   "source": [
    "tfidf_file_train = INTERIM_DATA_DIR / \"tfidf_train.parquet\"\n",
    "tfidf_file_test = INTERIM_DATA_DIR / \"tfidf_test.parquet\"\n",
    "\n",
    "if not tfidf_file_train.exists() or not tfidf_file_test.exists():\n",
    "    print(\"Generating TF-IDF features...\")\n",
    "    vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "    \n",
    "    tfidf_matrix_train = vectorizer.fit_transform(df_train['full_text'])\n",
    "    tfidf_df_train = pd.DataFrame(\n",
    "        tfidf_matrix_train.toarray(),\n",
    "        columns=[f\"tfidf_{i}\" for i in range(tfidf_matrix_train.shape[1])]\n",
    "    )\n",
    "    tfidf_df_train.to_parquet(tfidf_file_train, index=False)\n",
    "    \n",
    "    tfidf_matrix_test = vectorizer.transform(df_test['full_text'])\n",
    "    tfidf_df_test = pd.DataFrame(\n",
    "        tfidf_matrix_test.toarray(),\n",
    "        columns=[f\"tfidf_{i}\" for i in range(tfidf_matrix_test.shape[1])]\n",
    "    )\n",
    "    tfidf_df_test.to_parquet(tfidf_file_test, index=False)\n",
    "    \n",
    "    joblib.dump(vectorizer, INTERIM_DATA_DIR / \"tfidf_vectorizer.joblib\")\n",
    "    print(\"TF-IDF features saved.\")\n",
    "else:  \n",
    "    print(\"TF-IDF features files already exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "id": "model-prep-header"
   },
   "source": [
    "## 4. Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "feature-assembly",
    "outputId": "122e1027-5756-4d5f-d1d4-2b4986316b41"
   },
   "outputs": [],
   "source": [
    "df_sentence_transformer_train = pd.read_parquet(INTERIM_DATA_DIR / \"sentence_embeddings_train.parquet\")\n",
    "df_sentence_transformer_test = pd.read_parquet(INTERIM_DATA_DIR / \"sentence_embeddings_test.parquet\")\n",
    "\n",
    "df_tf_idf_train = pd.read_parquet(INTERIM_DATA_DIR / \"tfidf_train.parquet\")\n",
    "df_tf_idf_test = pd.read_parquet(INTERIM_DATA_DIR / \"tfidf_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base features (non-text vector)\n",
    "tag_cols = [f'tag_{i}' for i in range(1, 9)]\n",
    "cols_to_drop = [\"subject\", \"body\", \"full_text\"] + tag_cols\n",
    "df_train = df_train.drop(columns=cols_to_drop)\n",
    "df_test = df_test.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistent label encoding - fit only on training data\n",
    "le = LabelEncoder()\n",
    "target_col = 'priority'\n",
    "\n",
    "# Fit encoder on training data only\n",
    "df_train[target_col] = le.fit_transform(df_train[target_col])\n",
    "\n",
    "# Transform test data using the fitted encoder\n",
    "df_test[target_col] = le.transform(df_test[target_col])\n",
    "\n",
    "print(f\"Target classes: {le.classes_}\")\n",
    "\n",
    "# Save the fitted encoder for future use\n",
    "joblib.dump(le, INTERIM_DATA_DIR / \"label_encoder.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final dataframes for each experiment\n",
    "df_st_train = pd.concat([df_train, df_sentence_transformer_train], axis=1)\n",
    "df_st_test = pd.concat([df_test, df_sentence_transformer_test], axis=1)\n",
    "df_tfidf_train = pd.concat([df_train, df_tf_idf_train], axis=1)\n",
    "df_tfidf_test = pd.concat([df_test, df_tf_idf_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dataset-prep-cell",
    "outputId": "fb66c400-ac53-438a-a1f2-915d5d41f0a8"
   },
   "outputs": [],
   "source": [
    "# --- TF-IDF Dataset ---\n",
    "X_train_tfidf = df_tfidf_train.drop(columns=[target_col])\n",
    "y_train_tfidf = df_tfidf_train[target_col]\n",
    "X_test_tfidf = df_tfidf_test.drop(columns=[target_col])\n",
    "y_test_tfidf = df_tfidf_test[target_col]\n",
    "\n",
    "# --- Sentence Transformer Dataset ---\n",
    "X_train_st = df_st_train.drop(columns=[target_col])\n",
    "y_train_st = df_st_train[target_col]\n",
    "X_test_st = df_st_test.drop(columns=[target_col])\n",
    "y_test_st = df_st_test[target_col]\n",
    "\n",
    "# Create a dictionary to hold the datasets for easy iteration\n",
    "datasets = {\n",
    "    \"TF-IDF\": (X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf),\n",
    "    \"SentenceTransformer\": (X_train_st, X_test_st, y_train_st, y_test_st)\n",
    "}\n",
    "\n",
    "print(\"Shapes for TF-IDF dataset:\")\n",
    "print(f\"X_train: {X_train_tfidf.shape}, y_train: {y_train_tfidf.shape}\")\n",
    "print(f\"X_test: {X_test_tfidf.shape}, y_test: {y_test_tfidf.shape}\")\n",
    "print(\"\\nShapes for SentenceTransformer dataset:\")\n",
    "print(f\"X_train: {X_train_st.shape}, y_train: {y_train_st.shape}\")\n",
    "print(f\"X_test: {X_test_st.shape}, y_test: {y_test_st.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "id": "model-training-header"
   },
   "source": [
    "## 5. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "id": "preprocessor-and-models-def"
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"logistic_l2\": LogisticRegression(\n",
    "        solver='lbfgs', \n",
    "        class_weight='balanced', \n",
    "        max_iter=1000, \n",
    "        random_state=42,\n",
    "        C=0.1, \n",
    "        penalty='l2', \n",
    "        multi_class='multinomial' \n",
    "    ),\n",
    "    \"random_forest\": RandomForestClassifier(\n",
    "        n_estimators=200,  # Increased number of trees\n",
    "        max_depth=15,  # Slightly increased depth\n",
    "        class_weight='balanced_subsample', \n",
    "        random_state=42, \n",
    "        n_jobs=-1,\n",
    "        min_samples_split=5,  \n",
    "        min_samples_leaf=2,  \n",
    "        max_features='sqrt',  \n",
    "        bootstrap=True,  \n",
    "        oob_score=True  \n",
    "    ),\n",
    "    \"xgboost\": XGBClassifier(\n",
    "        tree_method=\"hist\", \n",
    "        device=\"cuda\", \n",
    "        objective='multi:softprob', \n",
    "        num_class=3, \n",
    "        n_estimators=200,  \n",
    "        learning_rate=0.05,  \n",
    "        max_depth=6,  \n",
    "        eval_metric='mlogloss', \n",
    "        random_state=42,\n",
    "        subsample=0.8,  \n",
    "        colsample_bytree=0.8,  \n",
    "        reg_alpha=0.1,  \n",
    "        reg_lambda=1.0,  \n",
    "        min_child_weight=1  \n",
    "    ),\n",
    "    \"lightgbm\": LGBMClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=7,\n",
    "        num_leaves=31,  # Maximum tree leaves for base learners\n",
    "        subsample=0.8,  # Subsample ratio of the training instances\n",
    "        colsample_bytree=0.8,  # Subsample ratio of columns when constructing each tree\n",
    "        reg_alpha=0.1,  # L1 regularization\n",
    "        reg_lambda=0.1,  # L2 regularization\n",
    "        min_child_samples=20,  # Minimum number of data needed in a child (leaf)\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"catboost\": CatBoostClassifier(\n",
    "        random_state=42,\n",
    "        iterations=200,  # Number of trees\n",
    "        learning_rate=0.05,\n",
    "        depth=6,  # Depth of the trees\n",
    "        l2_leaf_reg=3,  # L2 regularization term\n",
    "        border_count=128,  # Number of splits for numerical features\n",
    "        loss_function='MultiClass',  # For multiclass classification\n",
    "        verbose=0,  # To suppress output\n",
    "        auto_class_weights='Balanced'  # Handles class imbalance\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d_name, (X_train, X_test, y_train, y_test) in datasets.items():\n",
    "    print(\"=\"*50)\n",
    "    print(f\"RESULTS FOR FEATURE SET: {d_name}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    categorical_features = ['type', 'queue', 'language', 'queue_type_interaction']\n",
    "    numerical_features = [col for col in X_train.columns if col not in categorical_features]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_features),\n",
    "            (\"num\", StandardScaler(), numerical_features)\n",
    "        ],\n",
    "        remainder=\"passthrough\"\n",
    "    )\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        clf = Pipeline(steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"model\", model)\n",
    "        ])\n",
    "\n",
    "        # Handle different models with their specific requirements\n",
    "        if model_name == \"xgboost\" or model_name == \"lightgbm\" or model_name == \"catboost\":\n",
    "            sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "            clf.fit(X_train, y_train, model__sample_weight=sample_weights)\n",
    "        else:\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        print(f\"\\n--- Model: {model_name} ---\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "        \n",
    "        # Additional metrics\n",
    "        if hasattr(clf, 'predict_proba'):\n",
    "            try:\n",
    "                y_proba = clf.predict_proba(X_test)\n",
    "                print(f\"ROC AUC: {roc_auc_score(y_test, y_proba, multi_class='ovr'):.4f}\")\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "id": "hyperparam-tuning-header"
   },
   "source": [
    "## 6. Hyperparameter Tuning (XGBoost)\n",
    "\n",
    "Based on the results above, we select the best combination (e.g., SentenceTransformer features with XGBoost) and perform a more rigorous hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gridsearch-setup",
    "outputId": "a8560f84-0fcb-4c4d-e2f5-41665043ca94"
   },
   "outputs": [],
   "source": [
    "X_train_tune, X_test_tune, y_train_tune, y_test_tune = datasets['SentenceTransformer']\n",
    "\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', XGBClassifier(\n",
    "        tree_method = \"hist\", device = \"cuda\", objective='multi:softprob', num_class=3, eval_metric='mlogloss', random_state=42\n",
    "    )\n",
    "    )\n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    'model__max_depth': randint(4, 8),\n",
    "    'model__learning_rate': uniform(0.01, 0.2),\n",
    "    'model__n_estimators': randint(100, 400),\n",
    "    'model__subsample': uniform(0.5, 0.5),        \n",
    "    'model__colsample_bytree': uniform(0.5, 0.5)\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=15,\n",
    "    scoring='f1_weighted',\n",
    "    cv=cv,\n",
    "    n_jobs=1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Starting RandomizedSearchCV for XGBoost with SentenceTransformer features...\")\n",
    "sample_weights_tune = compute_sample_weight(class_weight='balanced', y=y_train_tune)\n",
    "random_search.fit(X_train_tune, y_train_tune, model__sample_weight=sample_weights_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gridsearch-results",
    "outputId": "ec6dcc8d-d9a4-4eba-efd6-fc13ec17353c"
   },
   "outputs": [],
   "source": [
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best cross-validation F1-weighted score: \", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "id": "final-eval-header"
   },
   "source": [
    "## XGBOOST Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "final-report",
    "outputId": "eba4d9ab-a34c-44a3-c06a-fde714ece034"
   },
   "outputs": [],
   "source": [
    "best_model = random_search.best_estimator_\n",
    "joblib.dump(best_model, 'best_xgboost_model.joblib')\n",
    "\n",
    "y_pred_final = best_model.predict(X_test_tune)\n",
    "print(f'accurcy socres: {accuracy_score(y_test_tune, y_pred_final):.4f}')\n",
    "print(\"Final Classification Report for the Tuned XGBoost Model:\")\n",
    "print(classification_report(y_test_tune, y_pred_final, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "confusion-matrix-plot",
    "outputId": "8030d5a2-d54a-4d48-d775-4851cf99d75c"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test_tune, y_pred_final)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt='d', cmap='Blues',\n",
    "    xticklabels=le.classes_, yticklabels=le.classes_\n",
    ")\n",
    "plt.title('Confusion Matrix for Best Tuned Model')\n",
    "plt.ylabel('Actual Priority')\n",
    "plt.xlabel('Predicted Priority')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning (Random Forest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f788ad6",
    "outputId": "ae371b7a-35ab-4406-b5d3-0b939854bfa1"
   },
   "outputs": [],
   "source": [
    "X_train_tune, X_test_tune, y_train_tune, y_test_tune = datasets['SentenceTransformer']\n",
    "\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        class_weight='balanced'\n",
    "    ))\n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    'model__n_estimators': randint(100, 400),\n",
    "    'model__max_depth': [10, 20, 30, None],\n",
    "    'model__min_samples_split': randint(2, 11),\n",
    "    'model__min_samples_leaf': randint(1, 5),\n",
    "    'model__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Set up Stratified K-Fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Set up RandomSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf_pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=15,\n",
    "    scoring='f1_weighted',\n",
    "    cv=cv,\n",
    "    n_jobs=1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Starting RandomizedSearchCV for RandomForest with SentenceTransformer features...\")\n",
    "\n",
    "random_search.fit(X_train_tune, y_train_tune)\n",
    "\n",
    "print(\"\\n RandomizedSearchCV for RandomForest finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best parameters found: {random_search.best_params_}\")\n",
    "print(f\"Best weighted F1-score from CV: {random_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8nKRBo81TU_",
    "outputId": "62a3a1f8-b25d-418d-8f4f-9f5b3dcb5dfd"
   },
   "outputs": [],
   "source": [
    "joblib.dump(best_rf_model, 'best_rf_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "## 7. RANDOM FOREST Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8b22d85",
    "outputId": "de194fd0-c2dd-47b5-b76d-bfc9be9ad5e8"
   },
   "outputs": [],
   "source": [
    "y_pred_final = best_rf_model.predict(X_test_tune)\n",
    "print(f\"\\nWeighted F1-score on the test set: {f1_score(y_test_tune, y_pred_final, average='weighted'):.4f}\")\n",
    "print(f'accurcy socres: {accuracy_score(y_test_tune, y_pred_final):.4f}')\n",
    "\n",
    "print(\"Final Classification Report for the Tuned Random Forest Model:\")\n",
    "print(classification_report(y_test_tune, y_pred_final, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "65c5d329",
    "outputId": "09d37159-32d4-48d6-edd9-97ac008699a3"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test_tune, y_pred_final)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt='d', cmap='Blues',\n",
    "    xticklabels=le.classes_, yticklabels=le.classes_\n",
    ")\n",
    "plt.title('Confusion Matrix for Best Tuned Model')\n",
    "plt.ylabel('Actual Priority')\n",
    "plt.xlabel('Predicted Priority')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## Threshold Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Threshold Tuning for 'low' class recall ---\n",
    "print(\"\\n--- Starting Threshold Tuning for 'low' class ---\")\n",
    "\n",
    "y_proba = best_rf_model.predict_proba(X_test_tune)\n",
    "\n",
    "# Ensure class order matches label encoder (high, low, medium)\n",
    "class_names = le.classes_ # Should be ['high', 'low', 'medium']\n",
    "try:\n",
    "    low_class_index = np.where(class_names == 'low')[0][0]\n",
    "    high_class_index = np.where(class_names == 'high')[0][0]\n",
    "    medium_class_index = np.where(class_names == 'medium')[0][0]\n",
    "except IndexError:\n",
    "    print(\"Error: Could not find 'low', 'high', or 'medium' class in label encoder.\")\n",
    "    raise\n",
    "\n",
    "# --- Corrected Threshold Tuning Loop ---\n",
    "thresholds = np.arange(0.10, 0.51, 0.01)\n",
    "\n",
    "# Initialize variables to store best results\n",
    "best_threshold = 0.0\n",
    "best_weighted_f1 = 0.0\n",
    "y_pred_best_thresh = y_pred_final # Start with the original best predictions\n",
    "original_weighted_f1 = f1_score(y_test_tune, y_pred_final, average='weighted')\n",
    "\n",
    "print(f\"Original Weighted F1-Score: {original_weighted_f1:.4f}\")\n",
    "\n",
    "# Iterate through thresholds\n",
    "for thresh in thresholds:\n",
    "    # 1. Initialize predictions with a placeholder\n",
    "    y_pred_thresh = np.zeros(len(y_test_tune), dtype=int)\n",
    "\n",
    "    # 2. Find all rows where the 'low' probability is above the current threshold\n",
    "    low_mask = y_proba[:, low_class_index] >= thresh\n",
    "\n",
    "    # 3. For those rows, assign the 'low' class directly\n",
    "    y_pred_thresh[low_mask] = low_class_index\n",
    "\n",
    "    # 4. For all other rows, decide between 'high' and 'medium'\n",
    "    not_low_mask = ~low_mask\n",
    "    # Create a temporary probability array for non-low predictions\n",
    "    temp_proba = y_proba[not_low_mask].copy()\n",
    "    # Set the 'low' class probability to zero to ensure it's not chosen\n",
    "    temp_proba[:, low_class_index] = 0\n",
    "    \n",
    "    # Predict the remaining classes based on the highest remaining probability\n",
    "    if temp_proba.shape[0] > 0:\n",
    "        remaining_preds = np.argmax(temp_proba, axis=1)\n",
    "        y_pred_thresh[not_low_mask] = remaining_preds\n",
    "\n",
    "    # 5. Calculate the score and update if it's the best\n",
    "    current_weighted_f1 = f1_score(y_test_tune, y_pred_thresh, average='weighted')\n",
    "\n",
    "    if current_weighted_f1 > best_weighted_f1:\n",
    "        best_weighted_f1 = current_weighted_f1\n",
    "        best_threshold = thresh\n",
    "        y_pred_best_thresh = y_pred_thresh.copy()\n",
    "\n",
    "# 5. Report results\n",
    "print(f\"\\nBest Threshold for 'low' class: {best_threshold:.2f}\")\n",
    "print(f\"Best Weighted F1-Score achieved: {best_weighted_f1:.4f}\")\n",
    "print(f\"Improvement: {best_weighted_f1 - original_weighted_f1:.4f}\")\n",
    "\n",
    "# 6. (Optional) Print the classification report for the best threshold\n",
    "if 'y_pred_best_thresh' in locals():\n",
    "    print(\"\\nClassification Report for Best Threshold Tuned Model:\")\n",
    "    print(classification_report(y_test_tune,   y_pred_best_thresh, target_names=class_names))\n",
    "else:\n",
    "    print(\"\\nNo improvement found, best threshold remains at 0.5 (default).\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
